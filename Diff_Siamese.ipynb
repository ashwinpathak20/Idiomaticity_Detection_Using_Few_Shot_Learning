{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gXdCtnjq1PK",
        "outputId": "916bec38-f002-4ac9-f1a8-49b58d4eafb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemEval_2022_Task2-idiomaticity'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 92 (delta 31), reused 67 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR9ljCJSq3om",
        "outputId": "b1d58f39-85ab-4701-cd00-38ab9aaae1ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AStitchInLanguageModels'...\n",
            "remote: Enumerating objects: 1030, done.\u001b[K\n",
            "remote: Counting objects: 100% (1030/1030), done.\u001b[K\n",
            "remote: Compressing objects: 100% (772/772), done.\u001b[K\n",
            "remote: Total 1030 (delta 382), reused 803 (delta 202), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1030/1030), 79.86 MiB | 46.92 MiB/s, done.\n",
            "Resolving deltas: 100% (382/382), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1OczNFNq4_7",
        "outputId": "68de95d2-6a2b-4a50-c4fc-260bf6946f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 91582, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 91582 (delta 8), reused 17 (delta 1), pack-reused 91544\u001b[K\n",
            "Receiving objects: 100% (91582/91582), 75.77 MiB | 33.03 MiB/s, done.\n",
            "Resolving deltas: 100% (66079/66079), done.\n",
            "/content/transformers\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 474 kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 80.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 88.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.14.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.14.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.0.dev0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!pip install --editable .\n",
        "%cd /content/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVN0vrZTq6oX",
        "outputId": "5f1f4e0b-4455-4136-c898-6513091ef660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.2.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 85.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 82.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 84.1 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 97.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 77.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.16.1 frozenlist-1.2.0 fsspec-2021.11.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jj_uaj3aq8Od"
      },
      "outputs": [],
      "source": [
        "import site\n",
        "site.main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gSUai3g0q-Ji"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jst76TcOq_kX"
      },
      "outputs": [],
      "source": [
        "def load_csv( path, delimiter=',' ) : \n",
        "  header = None\n",
        "  data   = list()\n",
        "  with open( path, encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader( csvfile, delimiter=delimiter ) \n",
        "    for row in reader : \n",
        "      if header is None : \n",
        "        header = row\n",
        "        continue\n",
        "      data.append( row ) \n",
        "  return header, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P6SA-GvKrBSY"
      },
      "outputs": [],
      "source": [
        "def write_csv( data, location ) : \n",
        "  with open( location, 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer( csvfile ) \n",
        "    writer.writerows( data ) \n",
        "  print( \"Wrote {}\".format( location ) ) \n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KHJHosMVVNXS"
      },
      "outputs": [],
      "source": [
        "class Node():\n",
        "  def __init__(self, sentence, label):\n",
        "    self.sentence = sentence\n",
        "    self.label = label\n",
        "\n",
        "def create_idiom_dict_train(data_location, file_name) :\n",
        "    idiom_dict = {}\n",
        "    file_name = os.path.join( data_location, file_name ) \n",
        "    header, data = load_csv( file_name )\n",
        "    for elem in data:\n",
        "        label     = elem[ header.index( 'Label'  ) ]\n",
        "        sentence = elem[ header.index( 'Target' ) ]\n",
        "        idiom = elem[ header.index( 'MWE' ) ]\n",
        "        if idiom in idiom_dict:\n",
        "          idiom_dict[idiom].append(Node(sentence, label))\n",
        "        else:\n",
        "          idiom_dict[idiom] = [Node(sentence, label)]\n",
        "    return idiom_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xWO_TnshqY21"
      },
      "outputs": [],
      "source": [
        "d1 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_zero_shot.csv')\n",
        "d2 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_one_shot.csv')\n",
        "for key, value in d2.items():\n",
        "  if key in d1:\n",
        "    d1[key].append(value)\n",
        "  else:\n",
        "    d1[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JvkkIptrrDsB"
      },
      "outputs": [],
      "source": [
        "def _get_train_data( data_location, file_name, include_context, include_idiom ) :\n",
        "    \n",
        "    file_name = os.path.join( data_location, file_name ) \n",
        "\n",
        "    header, data = load_csv( file_name )\n",
        "\n",
        "    out_header = [ 'label1', 'label2', 'sentence1', 'sentence3' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label1', 'label2', 'sentence1', 'sentence2', 'sentence3', 'sentence4' ]\n",
        "        \n",
        "    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n",
        "    out_data = list()\n",
        "    for elem1 in data :\n",
        "        label     = elem1[ header.index( 'Label'  ) ]\n",
        "        sentence1 = elem1[ header.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem1[ header.index( 'Previous' ) ], elem1[ header.index( 'Target' ) ], elem1[ header.index( 'Next' ) ] ] )\n",
        "        for elem2 in d1[elem1[ header.index( 'MWE' ) ]]:\n",
        "          if elem2.sentence != sentence1:\n",
        "              label2     = elem2.label\n",
        "              sentence2 = elem2.sentence\n",
        "              this_row = None\n",
        "              if not include_idiom :\n",
        "                  this_row = [ label, label2, sentence1, sentence2 ] \n",
        "              else :\n",
        "                  sentence3 = elem1[ header.index( 'MWE' ) ]\n",
        "                  sentence4 = sentence3\n",
        "                  this_row = [ label, label2, sentence1, sentence3, sentence2, sentence4]\n",
        "              out_data.append( this_row )\n",
        "              assert len( out_header ) == len( this_row )\n",
        "    return [ out_header ] + out_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rMWvYWX8rGsu"
      },
      "outputs": [],
      "source": [
        "def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n",
        "\n",
        "    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n",
        "    gold_header  = gold_data = None\n",
        "    if not gold_file_name is None : \n",
        "        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n",
        "        assert len( input_data ) == len( gold_data )\n",
        "\n",
        "    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
        "    # ['ID', 'DataID', 'Language', 'Label']\n",
        "    \n",
        "    out_header = [ 'label1', 'label2', 'sentence1', 'sentence3' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label1', 'label2', 'label3', 'sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5', 'sentence6', 'language' ]\n",
        "\n",
        "    out_data = list()\n",
        "    for index in range( len( input_data ) ) :\n",
        "        label = 1\n",
        "        if not gold_file_name is None : \n",
        "            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n",
        "            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n",
        "            assert this_input_id == this_gold_id\n",
        "            \n",
        "            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n",
        "            language = gold_data[index][gold_header.index('Language')]\n",
        "        elem      = input_data[ index ]\n",
        "        sentence1 = elem[ input_headers.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ] \n",
        "        else :\n",
        "            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        idiom = elem[ input_headers.index( 'MWE' ) ]\n",
        "        other_nodes = d1[idiom]\n",
        "        if(len(other_nodes)==1):\n",
        "            if not include_idiom :\n",
        "                this_row = [ label, other_nodes[0].label, sentence1, other_nodes[0].sentence ] \n",
        "            else :\n",
        "                sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "                this_row = [ label, other_nodes[0].label, other_nodes[0].label, sentence1, sentence2, other_nodes[0].sentence, sentence2, other_nodes[0].sentence, sentence2, language ]\n",
        "        else:\n",
        "            if not include_idiom :\n",
        "                this_row = [ label, other_nodes[0].label, sentence1, other_nodes[0].sentence ] \n",
        "            else :\n",
        "                sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "                this_row = [ label, other_nodes[0].label, other_nodes[1].label, sentence1, sentence2, other_nodes[0].sentence, sentence2, other_nodes[1].sentence, sentence2, language ]\n",
        "           \n",
        "        assert len( out_header ) == len( this_row ) \n",
        "        out_data.append( this_row )\n",
        "        \n",
        "\n",
        "    return [ out_header ] + out_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U4bPrXRRrJ6H"
      },
      "outputs": [],
      "source": [
        "def create_data( input_location, output_location ) :\n",
        "\n",
        "    \n",
        "    ## Zero shot data\n",
        "    train_data = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False\n",
        "    )\n",
        "    write_csv( train_data, os.path.join( output_location, 'ZeroShot', 'train.csv' ) )\n",
        "    \n",
        "    dev_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv', \n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )        \n",
        "    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n",
        "    \n",
        "    eval_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )\n",
        "    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n",
        "\n",
        "\n",
        "    ## OneShot Data (combine both for training)\n",
        "    train_zero_data = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = False,\n",
        "        include_idiom   = True\n",
        "    )\n",
        "    train_one_data = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_one_shot.csv',\n",
        "        include_context = False,\n",
        "        include_idiom   = True\n",
        "    )\n",
        "\n",
        "    assert train_zero_data[0] == train_one_data[0] ## Headers\n",
        "    train_data = train_one_data + train_zero_data[1:]\n",
        "    write_csv( train_data, os.path.join( output_location, 'OneShot', 'train.csv' ) )\n",
        "    \n",
        "    dev_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv', \n",
        "        include_context  = False,\n",
        "        include_idiom    = True\n",
        "    )        \n",
        "    write_csv( dev_data, os.path.join( output_location, 'OneShot', 'dev.csv' ) )\n",
        "    \n",
        "    eval_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None,\n",
        "        include_context  = False,\n",
        "        include_idiom    = True\n",
        "    )\n",
        "    write_csv( eval_data, os.path.join( output_location, 'OneShot', 'eval.csv' ) )\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7t8zqdt9zAQo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0a6c0a33-f1fe-49cd-dcee-fc0b7fc2aa4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"eval_data = _get_dev_eval_data(\\n        data_location    = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\\n        input_file_name  = 'eval.csv',\\n        gold_file_name   = None,\\n        include_context  = False,\\n        include_idiom    = True\\n    )\""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_zero_data = _get_train_data(\n",
        "        data_location   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = False,\n",
        "        include_idiom   = True\n",
        "    )\n",
        "train_one_data = _get_train_data(\n",
        "        data_location   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n",
        "        file_name       = 'train_one_shot.csv',\n",
        "        include_context = False,\n",
        "        include_idiom   = True\n",
        "    )\n",
        "\n",
        "assert train_zero_data[0] == train_one_data[0] ## Headers\n",
        "train_data = train_one_data + train_zero_data[1:]\n",
        "\n",
        "dev_data = _get_dev_eval_data(\n",
        "        data_location    = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv', \n",
        "        include_context  = False,\n",
        "        include_idiom    = True\n",
        "    )        \n",
        "    \n",
        "\"\"\"eval_data = _get_dev_eval_data(\n",
        "        data_location    = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None,\n",
        "        include_context  = False,\n",
        "        include_idiom    = True\n",
        "    )\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnJSMleDrO64",
        "outputId": "d69fcfaa-d398-4169-bda1-b285a8cd7744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AStitchInLanguageModels  SemEval_2022_Task2-idiomaticity\n",
            "sample_data\t\t transformers\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AW_HqBIFrPbE"
      },
      "outputs": [],
      "source": [
        "outpath = 'Data'\n",
        "\n",
        "Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "183UBr4ArRSh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import logging\n",
        "\n",
        "from typing          import Optional\n",
        "from dataclasses     import dataclass, field\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "from datasets        import load_dataset, load_metric\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    EvalPrediction,\n",
        "    HfArgumentParser,\n",
        "    PretrainedConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    default_data_collator,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.utils         import check_min_version\n",
        "from transformers.trainer_utils import get_last_checkpoint, is_main_process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qtZiIQ5SrXBd"
      },
      "outputs": [],
      "source": [
        "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
        "check_min_version(\"4.6.0.dev0\")\n",
        "\n",
        "task_to_keys = {\n",
        "    \"cola\": (\"sentence\", None),\n",
        "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
        "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
        "    \"qnli\": (\"question\", \"sentence\"),\n",
        "    \"qqp\": (\"question1\", \"question2\"),\n",
        "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
        "    \"sst2\": (\"sentence\", None),\n",
        "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
        "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
        "}\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0EdhT3XrZCu",
        "outputId": "03fe2c45-65dd-47f6-fb19-d37beeae9812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['label1', 'label2', 'sentence1', 'sentence2', 'sentence3', 'sentence4'], ['0', '1', 'Program leaders said the scholarship defines public service broadly and imagines a variety of pathways toward civic engagement.', 'public service', 'In the ensuing years, Wennberg might not have managed to knock down the parking deck, but his administration helped keep Central Vermont Public Service from moving its corporate headquarters out of the city, and after successfully fighting a number of shopping centers city officials worried would pose a threat to downtown, he negotiated a deal that kept Diamond Run Mall from hosting a movie theater or supermarket and got the city a couple million dollars in payments that funded a variety of projects through the years.', 'public service']]\n"
          ]
        }
      ],
      "source": [
        "print(train_data[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755,
          "referenced_widgets": [
            "748e9725c15941eaa827e9709d430d48",
            "80faa8737a4842fbadd21bd447c6b6ab",
            "e315f80916014ad4b02afd3e9647651f",
            "edeed2197e4a4ae78dedc41dc4480e6a",
            "d0dfb168fa3045819bd5162700024ce9",
            "9551b24aa6ff454ca4a810fb59943949",
            "1c3e3bdaab5b45358898a131a995adbd",
            "38d4774e429c4e7285c22b8995d5b3e4",
            "7a89c11f9ff34363b7ace9487520a99b",
            "31d71a97aa4e4086a54b9a21345d2587",
            "08ae2bedb6e34581a878617ecf9fd7f8",
            "47b5871d04fc426fbc7b0230ebcb7292",
            "9d68345370b64444856274637fc82736",
            "f9b9c715814f4244b1af4c2f65f91323",
            "96444de7ae7945eea6c349b42802c5a4",
            "c67f7be640264209a182e1ada212052e",
            "2ace4b218b684f32a585363959517c9e",
            "7a01a3e544074603b140b4a4ccd65859",
            "c1efdeb622be4edcbc9410dbdba27b92",
            "96d6103f457648dc92f6dc7aa449fd81",
            "6c91e875292543be809974090cb73c09",
            "fbd842f2835140698757f6ad0ef2ddfd",
            "1e7995a9799e4dceb7badc6cedd8f24d",
            "78575144c57d4005989177ca63843e50",
            "ba54c880f6d54e87b5d3502f109205a6",
            "d4ab88f211e14f46904b65e807833055",
            "a0b08eb91eba4136aec84b22732b3048",
            "ba0c2380824441a2a7fd9da1e1e6026e",
            "0815a9b1a84449da88247a22059b3ac9",
            "db5963f50e2840119380bb409868d80b",
            "fee6453107e544f5ab761438b4936b9a",
            "a33f229f9a8947c6a6bc041f5edfc5c8",
            "fb64a101fcde4153bd266e74f9c890c4"
          ]
        },
        "id": "0QJsCAgjzt-9",
        "outputId": "98d0602d-dd41-4b8c-fa35-fd46cd3a1585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input: Williams stars as a talk-radio personality named Gebriel.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "748e9725c15941eaa827e9709d430d48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47b5871d04fc426fbc7b0230ebcb7292",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e7995a9799e4dceb7badc6cedd8f24d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pre-process in separate steps.\n",
            "Tokenized input: ['<s>', '▁Williams', '▁star', 's', '▁as', '▁a', '▁talk', '-', 'radio', '▁personal', 'ity', '▁na', 'med', '▁Geb', 'riel', '.', '</s>']\n",
            "BERT input_ids: [0, 40478, 6057, 7, 237, 10, 22120, 9, 38446, 3357, 2481, 24, 4806, 64867, 159053, 5, 2]\n",
            "BERT input_ids padded: tensor([     0,  40478,   6057,      7,    237,     10,  22120,      9,  38446,\n",
            "          3357,   2481,     24,   4806,  64867, 159053,      5,      2,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n",
            "\n",
            "Pre-process in one step.\n",
            "BERT input_ids padded: tensor([     0,  40478,   6057,      7,    237,     10,  22120,      9,  38446,\n",
            "          3357,   2481,     24,   4806,  64867, 159053,      5,      2,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "\n",
        "model_name = \"xlm-roberta-base\"\n",
        "\n",
        "org_input = \"Williams stars as a talk-radio personality named Gebriel.\"\n",
        "\n",
        "print(\"Original input:\", org_input)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base',\n",
        "                                          cache_dir=None,\n",
        "                                          use_fast=True,\n",
        "                                          revision=\"main\",\n",
        "                                          use_auth_token=None,)\n",
        "\n",
        "# Pre-process in two steps. \n",
        "print(\"\\nPre-process in separate steps.\")\n",
        "\n",
        "# 1. Split a word into multiple sub-words, e.g. 'Gebriel' -> 'ge', '##bri', '##el'\n",
        "sub_word_list = tokenizer.tokenize(f\"{tokenizer.cls_token} {org_input} {tokenizer.sep_token} \")\n",
        "print(\"Tokenized input:\", sub_word_list)\n",
        "\n",
        "# 2. Pad the sentence to a fixed/max length\n",
        "max_len = 128\n",
        "sub_word_idx_list = tokenizer.convert_tokens_to_ids(sub_word_list)\n",
        "print(\"BERT input_ids:\", sub_word_idx_list)\n",
        "\n",
        "input_ids = pad_sequences([sub_word_idx_list], maxlen=max_len, \n",
        "                          value=tokenizer.pad_token_id, padding=\"post\", \n",
        "                          dtype=\"long\", truncating=\"post\")\n",
        "input_ids = torch.tensor(input_ids)\n",
        "print(\"BERT input_ids padded:\", input_ids[0])\n",
        "\n",
        "\n",
        "# Pre-process in one step (check out https://huggingface.co/transformers/preprocessing.html#base-use for more details). \n",
        "print(\"\\nPre-process in one step.\")\n",
        "\n",
        "encoded_input = tokenizer(org_input, padding='max_length', max_length = max_len, \n",
        "                          truncation=True, return_tensors=\"pt\")\n",
        "print('BERT input_ids padded:', encoded_input['input_ids'][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(data):\n",
        "    indices = list(range(len(data)))\n",
        "    random.shuffle(indices)\n",
        "    shuffled_data = []\n",
        "    for i in indices:\n",
        "        shuffled_data.append(data[i])\n",
        "    return shuffled_data"
      ],
      "metadata": {
        "id": "rxajbXyYtpJp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nUGKP2VK0PY6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "def preproces(input, tokenizer, max_len, batch_size, data_class=\"train\"):\n",
        "    input1 = []\n",
        "    input2 = []\n",
        "    label1 = []\n",
        "    label2 = []\n",
        "    for i in input:\n",
        "      \"\"\"if(i[1]!='1' and i[1]!='0'):\n",
        "        continue\"\"\"\n",
        "      label1.append(int(i[0]))\n",
        "      label2.append(int(i[1]))\n",
        "      args = (\n",
        "            (i[2], i[3])\n",
        "      )\n",
        "      input1.append(args)\n",
        "      args = (\n",
        "            (i[4], i[5])\n",
        "      )\n",
        "      input2.append(args)\n",
        "    encoded_input1 = tokenizer(input1, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n",
        "    encoded_input2 = tokenizer(input2, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n",
        "    \n",
        "    input_ids1 = encoded_input1['input_ids']\n",
        "    attention_mask1 = encoded_input1['attention_mask']\n",
        "    labels1 = torch.tensor(label1)\n",
        "\n",
        "    #print(input_ids1.size(), attention_mask1.size(), labels1.size())\n",
        "\n",
        "    input_ids2 = encoded_input2['input_ids']\n",
        "    attention_mask2 = encoded_input2['attention_mask']\n",
        "    labels2 = torch.tensor(label2)\n",
        "\n",
        "    #print(input_ids2.size(), attention_mask2.size(), labels2.size())\n",
        "    dataset_tensor = TensorDataset(input_ids1, attention_mask1, labels1, input_ids2, attention_mask2, labels2)\n",
        "\n",
        "    if data_class == \"train\":\n",
        "        sampler = RandomSampler(dataset_tensor)\n",
        "    else:\n",
        "        sampler = SequentialSampler(dataset_tensor)\n",
        "    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n",
        "\n",
        "    return dataloader\n",
        "#train_dataloader = preproces(train_data[1:], tokenizer, max_len, batch_size, data_class=\"train\")\n",
        "#dev_dataloader = preproces(eval_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")\n",
        "#test_dataloader = preproces(dev_Data[1:], tokenizer, max_len, batch_size, data_class=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uIP79MjDtx5r"
      },
      "outputs": [],
      "source": [
        "max_len = 512\n",
        "batch_size = 32\n",
        "def preproces_dev(input, tokenizer, max_len, batch_size, data_class=\"dev\"):\n",
        "    input1 = []\n",
        "    input2 = []\n",
        "    input3 = []\n",
        "    label1 = []\n",
        "    label2 = []\n",
        "    label3 = []\n",
        "    language = []\n",
        "    for i in input:\n",
        "      \"\"\"if(i[1]!='1' and i[1]!='0'):\n",
        "        continue\"\"\"\n",
        "      label1.append(int(i[0]))\n",
        "      label2.append(int(i[1]))\n",
        "      label3.append(int(i[2]))\n",
        "      args = (\n",
        "            (i[3], i[4])\n",
        "      )\n",
        "      input1.append(args)\n",
        "      args = (\n",
        "            (i[5], i[6])\n",
        "      )\n",
        "      input2.append(args)\n",
        "      args = (\n",
        "          (i[7], i[8])\n",
        "      )\n",
        "      input3.append(args)\n",
        "      if i[9]=='EN':\n",
        "        language.append(0)\n",
        "      else:\n",
        "        language.append(1)\n",
        "    encoded_input1 = tokenizer(input1, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n",
        "    encoded_input2 = tokenizer(input2, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n",
        "    encoded_input3 = tokenizer(input3, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n",
        "    input_ids1 = encoded_input1['input_ids']\n",
        "    attention_mask1 = encoded_input1['attention_mask']\n",
        "    labels1 = torch.tensor(label1)\n",
        "    print(input_ids1.size(), attention_mask1.size(), labels1.size())\n",
        "\n",
        "    input_ids2 = encoded_input2['input_ids']\n",
        "    attention_mask2 = encoded_input2['attention_mask']\n",
        "    labels2 = torch.tensor(label2)\n",
        "\n",
        "    print(input_ids2.size(), attention_mask2.size(), labels2.size())\n",
        "\n",
        "    input_ids3 = encoded_input3['input_ids']\n",
        "    attention_mask3 = encoded_input3['attention_mask']\n",
        "    labels3 = torch.tensor(label3)\n",
        "\n",
        "    print(input_ids3.size(), attention_mask3.size(), labels3.size())  \n",
        "    language = torch.tensor(language)  \n",
        "\n",
        "    dataset_tensor = TensorDataset(input_ids1, attention_mask1, labels1, input_ids2, attention_mask2, labels2, input_ids3, attention_mask3, labels3, language)\n",
        "\n",
        "    if data_class == \"train\":\n",
        "        sampler = RandomSampler(dataset_tensor)\n",
        "    else:\n",
        "        sampler = SequentialSampler(dataset_tensor)\n",
        "    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n",
        "\n",
        "    return dataloader\n",
        "#dev_dataloader = preproces_dev(dev_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GoS9OP9e0IcN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class SiameseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseModel, self).__init__()\n",
        "        \n",
        "        self.base_model = AutoModel.from_pretrained(\n",
        "            'xlm-roberta-base',\n",
        "            from_tf=bool(\".ckpt\" in 'xlm-roberta-base'),\n",
        "            config=config,\n",
        "            cache_dir=None,\n",
        "            revision=\"main\",\n",
        "            use_auth_token=None,\n",
        "        ).cuda()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.linear = nn.Linear(768, 2).cuda() # output features from bert is 768 and 2 is ur number of labels\n",
        "        \n",
        "    def forward(self, input_ids1, attn_mask1, input_ids2, attn_mask2):\n",
        "        #outputs1 = self.base_model(input_ids1, attention_mask=attn_mask1)[1]\n",
        "        #outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2)[1]\n",
        "        outputs1 = self.base_model(input_ids1, attention_mask=attn_mask1).last_hidden_state[:, 0]\n",
        "        outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2).last_hidden_state[:, 0]\n",
        "        difference = outputs1*outputs2\n",
        "        # You write you new head here\n",
        "        outputs = self.dropout(difference)\n",
        "        outputs = self.linear(outputs)\n",
        "        \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "05DDBBjOYzrs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def Eval(bert_model, dataloader):\n",
        "\n",
        "    bert_model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    predictions_en, true_labels_en = [], []\n",
        "    predictions_pt, true_labels_pt = [], []\n",
        "    num_correct = 0\n",
        "    \n",
        "    for step, batch in enumerate(tqdm(dataloader)):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            logits1 = nn.functional.softmax(bert_model.forward(batch[0], batch[1], batch[3], batch[4]), -1)\n",
        "        with torch.no_grad():\n",
        "            logits2 = nn.functional.softmax(bert_model.forward(batch[0], batch[1], batch[6], batch[7]), -1)\n",
        "        logits = torch.cat((logits1, logits2), dim=1)\n",
        "        max_args = torch.argmax(logits, dim=1)\n",
        "        batch_predictions = []\n",
        "        batch_true_labels = batch[2]\n",
        "        first_sentence_labels = batch[5]\n",
        "        second_sentence_labels = batch[8]\n",
        "        batch_en_predictions = []\n",
        "        batch_pt_predictions = []\n",
        "        true_en_predictions = []\n",
        "        true_pt_predictions = []\n",
        "        language = batch[9]\n",
        "        for idx, instance in enumerate(max_args):\n",
        "          if instance == 0:\n",
        "            batch_predictions.append((first_sentence_labels[idx] - 1) * -1) # 0, 1 toggle\n",
        "            if language[idx].item() == 0:\n",
        "              batch_en_predictions.append((first_sentence_labels[idx] - 1) * -1)\n",
        "              true_en_predictions.append(batch_true_labels[idx])\n",
        "            else:\n",
        "              batch_pt_predictions.append((first_sentence_labels[idx] - 1) * -1)\n",
        "              true_pt_predictions.append(batch_true_labels[idx])\n",
        "          elif instance == 1:\n",
        "            batch_predictions.append(first_sentence_labels[idx])\n",
        "            if language[idx].item() == 0:\n",
        "              batch_en_predictions.append(first_sentence_labels[idx])\n",
        "              true_en_predictions.append(batch_true_labels[idx])\n",
        "            else:\n",
        "              batch_pt_predictions.append(first_sentence_labels[idx])\n",
        "              true_pt_predictions.append(batch_true_labels[idx])\n",
        "          elif instance == 2:\n",
        "            batch_predictions.append((second_sentence_labels[idx] - 1) * -1)\n",
        "            if language[idx].item() == 0:\n",
        "              batch_en_predictions.append((second_sentence_labels[idx] - 1) * -1)\n",
        "              true_en_predictions.append(batch_true_labels[idx])\n",
        "            else:\n",
        "              batch_pt_predictions.append((second_sentence_labels[idx] - 1) * -1)\n",
        "              true_pt_predictions.append(batch_true_labels[idx])\n",
        "          else:\n",
        "            batch_predictions.append(second_sentence_labels[idx])\n",
        "            if language[idx].item() == 0:\n",
        "              batch_en_predictions.append(second_sentence_labels[idx])\n",
        "              true_en_predictions.append(batch_true_labels[idx])\n",
        "            else:\n",
        "              batch_pt_predictions.append(second_sentence_labels[idx])\n",
        "              true_pt_predictions.append(batch_true_labels[idx])\n",
        "        predictions += batch_predictions\n",
        "        true_labels += batch_true_labels\n",
        "        predictions_en += batch_en_predictions\n",
        "        predictions_pt += batch_pt_predictions\n",
        "        true_labels_en += true_en_predictions\n",
        "        true_labels_pt += true_pt_predictions\n",
        "    return true_labels, predictions, true_labels_en, predictions_en, true_labels_pt, predictions_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jYDcfd5eY2oR"
      },
      "outputs": [],
      "source": [
        "def metrics(true_labels, predictions):\n",
        "    pre = []\n",
        "    tl = []\n",
        "    num_correct = 0\n",
        "    for pred, true_label in zip(predictions, true_labels):\n",
        "        pre.append(int(pred.item()))\n",
        "        tl.append(int(true_label.item()))\n",
        "        if pred == true_label:\n",
        "            num_correct += 1\n",
        "    print(\"\\nAccuracy: %s\" % (float(num_correct) / float(len(true_labels))))\n",
        "    print(\"F1 Score \")\n",
        "    print(f1_score(tl, pre, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "np7YcOhL4IWQ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def Train(bert_model, train_data, lr, n_epoch, tokenizer, batch_size, max_len):\n",
        "\n",
        "    print(\"Start Training!\")\n",
        "    optimizer = AdamW(bert_model.parameters(), lr=lr)\n",
        "    bert_model.train()\n",
        "    dev_dataloader = preproces_dev(dev_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")\n",
        "    # TRAIN loop\n",
        "    for epoch in range(n_epoch):\n",
        "        shuffled_train_data = shuffle_data(train_data)\n",
        "        shuffled_train_data = preproces(shuffled_train_data, tokenizer, max_len, batch_size)\n",
        "        print(f\"\\nEpoch {epoch}\")\n",
        "        torch.cuda.empty_cache()\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        for step, batch in enumerate(tqdm(shuffled_train_data)):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            bert_model.zero_grad()\n",
        "            # forward pass\n",
        "            logits = bert_model.forward(batch[0], batch[1], batch[3], batch[4])\n",
        "            # print(loss)\n",
        "            loss = 0\n",
        "            target = torch.where(batch[2]==batch[5], 1, 0)\n",
        "            #target = target.reshape(-1,1)\n",
        "            loss = nn.functional.cross_entropy(logits, target)\n",
        "            \n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            # track train loss\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_steps += 1\n",
        "            #loss = loss.detach()\n",
        "            # update parameters\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "\n",
        "        # print train loss per epoch\n",
        "        print(\"Train loss on epoch {}: {}\\n\".format(epoch, tr_loss / nb_tr_steps))\n",
        "\n",
        "        # Dev set evaluation\n",
        "        #print(\"Evaluate on the dev set:\")\n",
        "        #Eval(bert_model, dev_data)\n",
        "        true_labels, predictions, true_labels_en, predictions_en, true_labels_pt, predictions_pt  = Eval(bert_model, dev_dataloader)\n",
        "        print(\"EN-PT\")\n",
        "        metrics(true_labels, predictions)\n",
        "        print(\"EN\")\n",
        "        metrics(true_labels_en, predictions_en)\n",
        "        print(\"PT\")\n",
        "        metrics(true_labels_pt, predictions_pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oAKW6e6m5IHy"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "        'xlm-roberta-base',\n",
        "        num_labels=2,\n",
        "        finetuning_task=None,\n",
        "        cache_dir=None,\n",
        "        revision=\"main\",\n",
        "        use_auth_token=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "cc6269ef331c4394b0710e3afa56ec49",
            "baefff8a80d94b04b9e4fd26a15cd8cd",
            "d51a7497ceb44b16bff19f46c5f10264",
            "7ca90eb64e2d4698b779e5b76ac9fc0f",
            "0eb32e706e2f493d981e686fb5aabc03",
            "76b6c62de7534b038600eb2e339712f0",
            "dfb740771ad745cc904f18326520a992",
            "a40313f1b16a4f269952acc78eb1e5ad",
            "11f37a4245d543e1be4b32330a4c568e",
            "32736bdd4afb4a799f886049538e04bf",
            "b5267cb6b1d440ed824f9f77b4038836"
          ]
        },
        "id": "ar64c-jf4rp-",
        "outputId": "e64571cf-1436-46b1-cc18-27c650964fd2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc6269ef331c4394b0710e3afa56ec49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training!\n",
            "torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n",
            "torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n",
            "torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n",
            "\n",
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 1879/2694 [43:26<18:53,  1.39s/it]"
          ]
        }
      ],
      "source": [
        "model = SiameseModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "learning_rate = 2e-5\n",
        "num_epoch = 3\n",
        "torch.cuda.empty_cache()\n",
        "max_len = 128\n",
        "batch_size = 32\n",
        "\n",
        "if n_gpu > 1:\n",
        "    model.to(device)\n",
        "    model = torch.nn.DataParallel(model)\n",
        "else:\n",
        "    model.cuda()\n",
        "\n",
        "Train(model, train_data[1:], learning_rate, num_epoch, tokenizer, batch_size, max_len)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Diff_Siamese.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "748e9725c15941eaa827e9709d430d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80faa8737a4842fbadd21bd447c6b6ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e315f80916014ad4b02afd3e9647651f",
              "IPY_MODEL_edeed2197e4a4ae78dedc41dc4480e6a",
              "IPY_MODEL_d0dfb168fa3045819bd5162700024ce9"
            ]
          }
        },
        "80faa8737a4842fbadd21bd447c6b6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e315f80916014ad4b02afd3e9647651f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9551b24aa6ff454ca4a810fb59943949",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c3e3bdaab5b45358898a131a995adbd"
          }
        },
        "edeed2197e4a4ae78dedc41dc4480e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38d4774e429c4e7285c22b8995d5b3e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a89c11f9ff34363b7ace9487520a99b"
          }
        },
        "d0dfb168fa3045819bd5162700024ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31d71a97aa4e4086a54b9a21345d2587",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 20.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08ae2bedb6e34581a878617ecf9fd7f8"
          }
        },
        "9551b24aa6ff454ca4a810fb59943949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c3e3bdaab5b45358898a131a995adbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38d4774e429c4e7285c22b8995d5b3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a89c11f9ff34363b7ace9487520a99b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31d71a97aa4e4086a54b9a21345d2587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08ae2bedb6e34581a878617ecf9fd7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47b5871d04fc426fbc7b0230ebcb7292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d68345370b64444856274637fc82736",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9b9c715814f4244b1af4c2f65f91323",
              "IPY_MODEL_96444de7ae7945eea6c349b42802c5a4",
              "IPY_MODEL_c67f7be640264209a182e1ada212052e"
            ]
          }
        },
        "9d68345370b64444856274637fc82736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9b9c715814f4244b1af4c2f65f91323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ace4b218b684f32a585363959517c9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a01a3e544074603b140b4a4ccd65859"
          }
        },
        "96444de7ae7945eea6c349b42802c5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1efdeb622be4edcbc9410dbdba27b92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96d6103f457648dc92f6dc7aa449fd81"
          }
        },
        "c67f7be640264209a182e1ada212052e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c91e875292543be809974090cb73c09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 31.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbd842f2835140698757f6ad0ef2ddfd"
          }
        },
        "2ace4b218b684f32a585363959517c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a01a3e544074603b140b4a4ccd65859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1efdeb622be4edcbc9410dbdba27b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96d6103f457648dc92f6dc7aa449fd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c91e875292543be809974090cb73c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbd842f2835140698757f6ad0ef2ddfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e7995a9799e4dceb7badc6cedd8f24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78575144c57d4005989177ca63843e50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba54c880f6d54e87b5d3502f109205a6",
              "IPY_MODEL_d4ab88f211e14f46904b65e807833055",
              "IPY_MODEL_a0b08eb91eba4136aec84b22732b3048"
            ]
          }
        },
        "78575144c57d4005989177ca63843e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba54c880f6d54e87b5d3502f109205a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba0c2380824441a2a7fd9da1e1e6026e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0815a9b1a84449da88247a22059b3ac9"
          }
        },
        "d4ab88f211e14f46904b65e807833055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db5963f50e2840119380bb409868d80b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fee6453107e544f5ab761438b4936b9a"
          }
        },
        "a0b08eb91eba4136aec84b22732b3048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a33f229f9a8947c6a6bc041f5edfc5c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.68M/8.68M [00:00&lt;00:00, 32.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb64a101fcde4153bd266e74f9c890c4"
          }
        },
        "ba0c2380824441a2a7fd9da1e1e6026e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0815a9b1a84449da88247a22059b3ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db5963f50e2840119380bb409868d80b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fee6453107e544f5ab761438b4936b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a33f229f9a8947c6a6bc041f5edfc5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb64a101fcde4153bd266e74f9c890c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc6269ef331c4394b0710e3afa56ec49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_baefff8a80d94b04b9e4fd26a15cd8cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d51a7497ceb44b16bff19f46c5f10264",
              "IPY_MODEL_7ca90eb64e2d4698b779e5b76ac9fc0f",
              "IPY_MODEL_0eb32e706e2f493d981e686fb5aabc03"
            ]
          }
        },
        "baefff8a80d94b04b9e4fd26a15cd8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d51a7497ceb44b16bff19f46c5f10264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76b6c62de7534b038600eb2e339712f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfb740771ad745cc904f18326520a992"
          }
        },
        "7ca90eb64e2d4698b779e5b76ac9fc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a40313f1b16a4f269952acc78eb1e5ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11f37a4245d543e1be4b32330a4c568e"
          }
        },
        "0eb32e706e2f493d981e686fb5aabc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32736bdd4afb4a799f886049538e04bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04G/1.04G [00:20&lt;00:00, 60.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5267cb6b1d440ed824f9f77b4038836"
          }
        },
        "76b6c62de7534b038600eb2e339712f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfb740771ad745cc904f18326520a992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a40313f1b16a4f269952acc78eb1e5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11f37a4245d543e1be4b32330a4c568e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32736bdd4afb4a799f886049538e04bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5267cb6b1d440ed824f9f77b4038836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}